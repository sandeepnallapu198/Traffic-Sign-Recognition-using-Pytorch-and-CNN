{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5l0ps4apiVb",
        "outputId": "3731da2e-d794-4bbc-bfba-8cd5cafd2622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Import required Libraries\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "roLyWS8Jr2yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import pathlib\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torchvision.models import squeezenet1_1\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.optim import Adam\n"
      ],
      "metadata": {
        "id": "U3zuDDDWqKpb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checking for device"
      ],
      "metadata": {
        "id": "IYeU4FDesUx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "BIVh-4zTrKhy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD0VCv40sfZa",
        "outputId": "5c69cb2c-9d06-4e6b-fc51-cdedb953e809"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transforms"
      ],
      "metadata": {
        "id": "C59vLmD-Q0Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = T.Compose([\n",
        "    T.Resize((150,150)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5,0.5,0.5],\n",
        "                [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "SIOJnXqDsgpx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "NrUWMpv1Q4IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/traffic_sign_classification_dataset/train'\n",
        "test_path = '/content/traffic_sign_classification_dataset/test'\n",
        "\n",
        "train_loader = DataLoader(torchvision.datasets.ImageFolder(train_path,transform = transformer),\n",
        "                          batch_size = 64,shuffle = True)\n",
        "test_loader = DataLoader(torchvision.datasets.ImageFolder(test_path,transform = transformer),\n",
        "                          batch_size = 32,shuffle = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "5lesjmlns7sV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categories\n",
        "root = pathlib.Path(train_path)\n",
        "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "metadata": {
        "id": "N1mwTy6tvhYg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnK0Je7jJnWu",
        "outputId": "a3428433-8b9c-4064-c3eb-5ad0a038896b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ALL_MOTOR_VEHICLE_PROHIBITED', 'AXLE_LOAD_LIMIT', 'BARRIER_AHEAD', 'BULLOCK_AND_HANDCART_PROHIBITED', 'BULLOCK_PROHIBITED', 'CATTLE', 'COMPULSARY_AHEAD', 'COMPULSARY_AHEAD_OR_TURN_LEFT', 'COMPULSARY_AHEAD_OR_TURN_RIGHT', 'COMPULSARY_CYCLE_TRACK', 'COMPULSARY_KEEP_LEFT', 'COMPULSARY_KEEP_RIGHT', 'COMPULSARY_MINIMUM_SPEED', 'COMPULSARY_SOUND_HORN', 'COMPULSARY_TURN_LEFT', 'COMPULSARY_TURN_LEFT_AHEAD', 'COMPULSARY_TURN_RIGHT', 'COMPULSARY_TURN_RIGHT_AHEAD', 'CROSS_ROAD', 'CYCLE_CROSSING', 'CYCLE_PROHIBITED', 'DANGEROUS_DIP', 'DIRECTION', 'FALLING_ROCKS', 'FERRY', 'GAP_IN_MEDIAN', 'GIVE_WAY', 'GUARDED_LEVEL_CROSSING', 'HANDCART_PROHIBITED', 'HEIGHT_LIMIT', 'HORN_PROHIBITED', 'HUMP_OR_ROUGH_ROAD', 'LEFT_HAIR_PIN_BEND', 'LEFT_HAND_CURVE', 'LEFT_REVERSE_BEND', 'LEFT_TURN_PROHIBITED', 'LENGTH_LIMIT', 'LOAD_LIMIT', 'LOOSE_GRAVEL', 'MEN_AT_WORK', 'NARROW_BRIDGE', 'NARROW_ROAD_AHEAD', 'NO_ENTRY', 'NO_PARKING', 'NO_STOPPING_OR_STANDING', 'OVERTAKING_PROHIBITED', 'PASS_EITHER_SIDE', 'PEDESTRIAN_CROSSING', 'PEDESTRIAN_PROHIBITED', 'PRIORITY_FOR_ONCOMING_VEHICLES', 'QUAY_SIDE_OR_RIVER_BANK', 'RESTRICTION_ENDS', 'RIGHT_HAIR_PIN_BEND', 'RIGHT_HAND_CURVE', 'RIGHT_REVERSE_BEND', 'RIGHT_TURN_PROHIBITED', 'ROAD_WIDENS_AHEAD', 'ROUNDABOUT', 'SCHOOL_AHEAD', 'SIDE_ROAD_LEFT', 'SIDE_ROAD_RIGHT', 'SLIPPERY_ROAD', 'SPEED_LIMIT_15', 'SPEED_LIMIT_20', 'SPEED_LIMIT_30', 'SPEED_LIMIT_40', 'SPEED_LIMIT_5', 'SPEED_LIMIT_50', 'SPEED_LIMIT_60', 'SPEED_LIMIT_70', 'SPEED_LIMIT_80', 'STAGGERED_INTERSECTION', 'STEEP_ASCENT', 'STEEP_DESCENT', 'STOP', 'STRAIGHT_PROHIBITED', 'TONGA_PROHIBITED', 'TRAFFIC_SIGNAL', 'TRUCK_PROHIBITED', 'TURN_RIGHT', 'T_INTERSECTION', 'UNGUARDED_LEVEL_CROSSING', 'U_TURN_PROHIBITED', 'WIDTH_LIMIT', 'Y_INTERSECTION']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(classes)"
      ],
      "metadata": {
        "id": "oQOrZJfTzAOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd3e6b3-b63d-4b24-bf48-5cc2efb50e7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Network\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=85):\n",
        "        super(ConvNet,self).__init__()\n",
        "        \n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "        \n",
        "        #Input shape= (256,3,150,150)\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "        \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "        \n",
        "        \n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "        \n",
        "        \n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Feed forwad function\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "            \n",
        "            \n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "            \n",
        "        output=output.view(-1,32*75*75)\n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output"
      ],
      "metadata": {
        "id": "Z0j4ikxX32mD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet(num_classes = 85).to(device)"
      ],
      "metadata": {
        "id": "HaTtdNDjGqvS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(),lr=0.001,weight_decay = 0.0001)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "yQOo_vxQGq53"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count = len(glob.glob(test_path+'/**/*.jpg'))"
      ],
      "metadata": {
        "id": "YYVi39QYHVE4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_count,test_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDE4G-EUHlOP",
        "outputId": "1c1962f1-fbf3-4a51-e230-e5a646fca6f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4438 1288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "mvaa_l8GHK0w"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "          images=Variable(images.cuda())\n",
        "          labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'Best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q05BIsjYGjFy",
        "outputId": "efe54638-44f1-4217-8096-95347366cee5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train Loss: tensor(37.4431) Train Accuracy: 0.25101397025687244 Test Accuracy: 0.3385093167701863\n",
            "Epoch: 1 Train Loss: tensor(5.9828) Train Accuracy: 0.5164488508337088 Test Accuracy: 0.4518633540372671\n",
            "Epoch: 2 Train Loss: tensor(3.4219) Train Accuracy: 0.6399278954484002 Test Accuracy: 0.5861801242236024\n",
            "Epoch: 3 Train Loss: tensor(1.6961) Train Accuracy: 0.7528165840468679 Test Accuracy: 0.6451863354037267\n",
            "Epoch: 4 Train Loss: tensor(1.0421) Train Accuracy: 0.8217665615141956 Test Accuracy: 0.65527950310559\n",
            "Epoch: 5 Train Loss: tensor(0.5415) Train Accuracy: 0.885984677782785 Test Accuracy: 0.7104037267080745\n",
            "Epoch: 6 Train Loss: tensor(0.4517) Train Accuracy: 0.905588102748986 Test Accuracy: 0.7096273291925466\n",
            "Epoch: 7 Train Loss: tensor(0.4873) Train Accuracy: 0.9062640829202343 Test Accuracy: 0.7406832298136646\n",
            "Epoch: 8 Train Loss: tensor(0.3058) Train Accuracy: 0.9380351509689049 Test Accuracy: 0.7546583850931677\n",
            "Epoch: 9 Train Loss: tensor(0.3091) Train Accuracy: 0.9488508337088779 Test Accuracy: 0.7515527950310559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint=torch.load('Best_checkpoint.model')\n",
        "model=ConvNet(num_classes=85)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "46yz6GYP5p59",
        "outputId": "76666cad-43f7-43e4-eccb-1da7a105da9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu3): ReLU()\n",
              "  (fc): Linear(in_features=180000, out_features=85, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction function\n",
        "def prediction(img_path,transformer):\n",
        "    \n",
        "    image=Image.open(img_path)\n",
        "    \n",
        "    image_tensor=transformer(image).float()\n",
        "    \n",
        "    \n",
        "    image_tensor=image_tensor.unsqueeze_(0)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        image_tensor.cuda()\n",
        "        \n",
        "    input=Variable(image_tensor)\n",
        "    \n",
        "    \n",
        "    output=model(input)\n",
        "    \n",
        "    index=output.data.numpy().argmax()\n",
        "    \n",
        "    pred=classes[index]\n",
        "    \n",
        "    return pred"
      ],
      "metadata": {
        "id": "uoLxW-suM_vG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_path = '/content/drive/MyDrive/Traffic signs/pred'\n",
        "images_path=glob.glob(pred_path+'/*.jpg')"
      ],
      "metadata": {
        "id": "6st-z6-uNBoX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dict={}\n",
        "\n",
        "for i in images_path:\n",
        "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transformer)"
      ],
      "metadata": {
        "id": "gO5r1ep7NG7N"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dict"
      ],
      "metadata": {
        "id": "9y62pg5Q5sWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78718ae-98c8-4176-c142-cfa4f63a0a09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'08010.jpg': 'COMPULSARY_AHEAD_OR_TURN_RIGHT',\n",
              " '11118.jpg': 'COMPULSARY_KEEP_RIGHT',\n",
              " '10011.jpg': 'COMPULSARY_KEEP_LEFT',\n",
              " '10074.jpg': 'COMPULSARY_KEEP_LEFT',\n",
              " '08011.jpg': 'COMPULSARY_AHEAD_OR_TURN_RIGHT',\n",
              " '11119.jpg': 'COMPULSARY_KEEP_RIGHT',\n",
              " '08009.jpg': 'COMPULSARY_AHEAD_OR_TURN_RIGHT',\n",
              " '10073.jpg': 'CROSS_ROAD',\n",
              " '19011.jpg': 'CYCLE_CROSSING',\n",
              " '20004.jpg': 'CYCLE_PROHIBITED',\n",
              " '23018.jpg': 'SCHOOL_AHEAD',\n",
              " '23017.jpg': 'FALLING_ROCKS',\n",
              " '23019.jpg': 'SPEED_LIMIT_30',\n",
              " '20006.jpg': 'NO_STOPPING_OR_STANDING',\n",
              " '20005.jpg': 'CYCLE_PROHIBITED',\n",
              " '78012.jpg': 'HUMP_OR_ROUGH_ROAD',\n",
              " '63044.jpg': 'SPEED_LIMIT_15',\n",
              " '78004.jpg': 'TRAFFIC_SIGNAL',\n",
              " '67084.jpg': 'SPEED_LIMIT_60',\n",
              " '78008.jpg': 'TRAFFIC_SIGNAL',\n",
              " '00015.jpg': 'ALL_MOTOR_VEHICLE_PROHIBITED',\n",
              " '67124.jpg': 'SPEED_LIMIT_30',\n",
              " '67120.jpg': 'SPEED_LIMIT_30',\n",
              " '67088.jpg': 'SPEED_LIMIT_50',\n",
              " '67092.jpg': 'SPEED_LIMIT_60',\n",
              " '67128.jpg': 'SPEED_LIMIT_50',\n",
              " '63048.jpg': 'SPEED_LIMIT_15',\n",
              " '00016.jpg': 'ALL_MOTOR_VEHICLE_PROHIBITED',\n",
              " '17026.jpg': 'COMPULSARY_TURN_RIGHT_AHEAD',\n",
              " '15016.jpg': 'COMPULSARY_TURN_LEFT_AHEAD',\n",
              " '15017.jpg': 'COMPULSARY_TURN_LEFT_AHEAD',\n",
              " '17024.jpg': 'COMPULSARY_KEEP_LEFT',\n",
              " '17025.jpg': 'COMPULSARY_TURN_RIGHT_AHEAD',\n",
              " '15018.jpg': 'COMPULSARY_TURN_LEFT_AHEAD',\n",
              " '18138.jpg': 'CROSS_ROAD',\n",
              " '18139.jpg': 'CROSS_ROAD',\n",
              " '18147.jpg': 'CROSS_ROAD',\n",
              " '18148.jpg': 'CROSS_ROAD',\n",
              " '21016.jpg': 'DANGEROUS_DIP',\n",
              " '21015.jpg': 'DANGEROUS_DIP',\n",
              " '22006.jpg': 'DIRECTION',\n",
              " '21014.jpg': 'DANGEROUS_DIP',\n",
              " '33019.jpg': 'LEFT_HAND_CURVE',\n",
              " '35014.jpg': 'LEFT_TURN_PROHIBITED',\n",
              " '35027.jpg': 'LEFT_TURN_PROHIBITED',\n",
              " '35015.jpg': 'LEFT_TURN_PROHIBITED',\n",
              " '35026.jpg': 'LEFT_TURN_PROHIBITED',\n",
              " '33018.jpg': 'LEFT_HAND_CURVE',\n",
              " '72018.jpg': 'STEEP_ASCENT',\n",
              " '80039.jpg': 'TURN_RIGHT',\n",
              " '74027.jpg': 'STOP',\n",
              " '80029.jpg': 'COMPULSARY_KEEP_LEFT',\n",
              " '64007.jpg': 'SPEED_LIMIT_20',\n",
              " '80030.jpg': 'TURN_RIGHT',\n",
              " '80041.jpg': 'TURN_RIGHT',\n",
              " '74029.jpg': 'STOP',\n",
              " '80027.jpg': 'COMPULSARY_KEEP_RIGHT',\n",
              " '72017.jpg': 'STEEP_ASCENT',\n",
              " '74030.jpg': 'STOP',\n",
              " '80042.jpg': 'TURN_RIGHT',\n",
              " '64009.jpg': 'SPEED_LIMIT_20',\n",
              " '83021.jpg': 'WIDTH_LIMIT',\n",
              " '83018.jpg': 'WIDTH_LIMIT',\n",
              " '83019.jpg': 'WIDTH_LIMIT',\n",
              " '82002.jpg': 'UNGUARDED_LEVEL_CROSSING',\n",
              " '82004.jpg': 'UNGUARDED_LEVEL_CROSSING',\n",
              " '82005.jpg': 'UNGUARDED_LEVEL_CROSSING'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhV01JcmYlTm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}